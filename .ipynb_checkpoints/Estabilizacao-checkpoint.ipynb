{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 2-1: Estabilização de imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leonardo Medeiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto consiste em implementar um programa que captura as imagens da webcam e realiza a estabilização da imagem, esta estabilização e feita através da compensação das imagens relativo aos movimentos dos componentes, para tal foram utilizados dois métodos distintos, de pontos notaveis e de densidade, que terão sua efetividade analisada perante os resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import cv2 as cv\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pontos Notavies - Optical Flow "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este método consiste em analisar os pontos notáveis da imagem para obter o fluxo ótico, foi utilizada a função goodFeaturesToTrack do opencv para obter esses pontos, para obter através de dois frames consecutivos o fluxo ótico foi utilizado a função calcOpticalFlowPyrLK do opencv que nos fornece esse parâmetro, porem como há diversos pontos na imagem com diferentes fluxos torna-se necessário realizar uma média para obter um valor de fluxo ótico mais próximo do real e acumular este valor de forma a gerar um vetor para que representa o fluxo ótico do primeiro frame ao último frame, finalmente para a estabilização da imagem está é deslocada em função do fluxo ótico acumulado na direção x e na direção y, que serve como parâmetro para ajustar os componentes do frame a posição inicial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = [0, 0]\n",
    "\n",
    "# Parametriza a funcao do OpenCV\n",
    "dt_params = dict( maxCorners = 100,\n",
    "                  qualityLevel = 0.3,\n",
    "                  minDistance = 7,\n",
    "                  blockSize = 7 )\n",
    "\n",
    "# Parametriza o Lucas-Kanade\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "\n",
    "def get_Traking(frame_inicial, frame, dt_params, lk_params):    \n",
    "    global vec\n",
    "    \n",
    "    # Gera cores de forma aleatória\n",
    "    color = np.random.randint(0,255,(100,3))\n",
    "    \n",
    "    previous_gray = cv.cvtColor(frame_inicial, cv.COLOR_BGR2GRAY)\n",
    "    p0 = cv.goodFeaturesToTrack(previous_gray, mask = None, **dt_params)#allter\n",
    "    \n",
    "    # Cria uma máscara para imprimir o rastro.\n",
    "    mask = np.zeros_like(frame_inicial)\n",
    "    \n",
    "    actual_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcula o Fluxo Otico\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(previous_gray, actual_gray, p0, None, **lk_params)\n",
    "    \n",
    "    # Seleciona somente os melhores pontos\n",
    "    good_new = p1[st==1]\n",
    "    good_old = p0[st==1]\n",
    "    \n",
    "    delta_x = []\n",
    "    delta_y = []\n",
    "    \n",
    "    # Desenha as trilhas para cada ponto em p1 e p0\n",
    "    for i,(new, old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv.line(mask,(a,b),(c,d), [0,0,255], 2)\n",
    "        frame = cv.circle(frame,(a,b),5,color[i].tolist(),-1)\n",
    "        \n",
    "        delta_x.append(a - c)\n",
    "        delta_y.append(b - d)\n",
    "        \n",
    "    \n",
    "    ##Calculo da media\n",
    "    if (len(delta_x) > 0 and len(delta_y) > 0):  \n",
    "        media_x = sum(delta_x)/len(delta_x)\n",
    "        media_y = sum(delta_y)/len(delta_y)\n",
    "    \n",
    "        vec[0] += media_x\n",
    "        vec[1] += media_y\n",
    "    \n",
    "    img = cv.add(frame, mask)\n",
    "    \n",
    "    ##deslocamento da imagem\n",
    "    M = np.array([[1, 0, -vec[0]], [0, 1, -vec[1]]], dtype=np.float32)\n",
    "    img = cv2.warpAffine(frame, M, (frame.shape[1], frame.shape[0]))  # Terceiro argumento é o tamanho da imagem resultante.\n",
    "\n",
    "    \n",
    "    return frame, img\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ao analisar o resultado obtido pelo método de pontos notáveis  tem-se que a estabilização da imagem é parcial e ocasionalmente falha, isso se deve pela razão de que os pontos da imagem podem se deslocar de forma inconsistente com o movimento, pois como este método considera pontos notáveis da imagem (como por exemplo bordas) devido a  luminosidade, os pontos do frame podem ser totalmente divergentes ao componente considerado no frame anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dense Optical Flow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para solucionar o problema dos pontos notáveis foi utilizado o dense optical flow, este método consiste em observar a todos os pontos da imagem, permitindo que a falha seja menor ao realizar um movimento, para isso foi utilizado a função calcOpticalFlowAarneback do opencv que ao receber dois frames consegue calcular a diferença da posição x e y dos pontos entre os frames. Para  diminuir interferências do fundo da imagem, assim como tornar o programa mais rápido diminuindo a quantidade de informação processadas, foi limitado apenas a área central da imagem para análise de fluxo, simulada visualmente por um retângulo, posteriormente calcula-se a média do fluxo ótico para obter um valor mais real e acumular este valor de forma a gerar um vetor que represente o fluxo optico do primeiro frame ao último frame, e por fim é aplicado o deslocamento da imagem com o vetor acumulado do fluxo optico.\n",
    "\n",
    "Como resultado do deslocamento obtém-se bordas pretas nas imagens, que foram retiradas com cortes na imagem de forma a manter sua proporção, como a imagem cortada possui tamanho variável e menor que o frame original foi utilizado o resize para manter o tamanho original, obtendo um efeito de zoom.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = [0, 0]\n",
    "\n",
    "def get_DenciveTraking(frame_anterior, frame):\n",
    "    global vec\n",
    "    y = frame.shape[0] \n",
    "    x = frame.shape[1]\n",
    "    \n",
    "    #Calcula o centro da imagem \n",
    "    cy = int(y/2)\n",
    "    cx = int(x/2)\n",
    "    rec = [70, 90]\n",
    "    \n",
    "    previous = cv2.cvtColor(frame_inicial, cv.COLOR_BGR2GRAY)\n",
    "    actual   = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Calcula o Fluxo Otico No Centro da Imagem Lititado Por Um Retangulo\n",
    "    flow = cv2.calcOpticalFlowFarneback(previous[cx - rec[0] + int(vec[0]) : cx + rec[0] + int(vec[0]), \n",
    "                                                 cy - rec[1] + int(vec[1]) : cy + rec[1] + int(vec[1])], \n",
    "                                          actual[cx - rec[0] + int(vec[0]) : cx + rec[0] + int(vec[0]),\n",
    "                                                 cy - rec[1] + int(vec[1]) : cy + rec[1] + int(vec[1])],\n",
    "                                                                            None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    #Calcula a Média\n",
    "    vec[0] += np.mean(np.mean(flow[:, :, 0]))\n",
    "    vec[1] += np.mean(np.mean(flow[:, :, 1]))\n",
    "   \n",
    "    #Deslocamento da Imagem\n",
    "    M = np.array([[1, 0, -vec[0]], [0, 1, -vec[1]]], dtype=np.float32)\n",
    "    img = cv2.warpAffine(frame, M, (x, y))\n",
    " \n",
    "    #Scaling\n",
    "    proporcao = x / y\n",
    "    corte_x = 0\n",
    "    corte_y = 0\n",
    "    \n",
    "    #Tamanha da nova imagem sem considerar a proporção\n",
    "    new_y = y - np.abs(vec[1])\n",
    "    new_x = x - np.abs(vec[0])\n",
    "    \n",
    "    #Corta a imagem considerando a proporção \n",
    "    if(np.abs(vec[0] / x) < np.abs(vec[1] / y)):\n",
    "        var = \"X_CT\"\n",
    "        corte_x = int( x - (proporcao * new_y) )\n",
    "        corte_y = int(y - new_y)\n",
    "        \n",
    "    elif(np.abs(vec[0] / x) > np.abs(vec[1] / y)):\n",
    "        var = \"Y_CT\"\n",
    "        corte_x = int(x - new_x)    \n",
    "        corte_y = int( y - (new_x / proporcao) )\n",
    "     \n",
    "    v_x = x - corte_x - 1\n",
    "    v_y = y - corte_y - 1\n",
    "\n",
    "    if(vec[0] > 0):\n",
    "        img = img[:,:v_x,:]\n",
    "\n",
    "    elif(vec[0] < 0):\n",
    "        img = img[:, corte_x:, :]\n",
    "    \n",
    "    else:\n",
    "        img = img[:, corte_x/2: (v_x + corte_x/2), :]\n",
    "        \n",
    "    if(vec[1] > 0):\n",
    "        img = img[:v_y,:,:]\n",
    "\n",
    "    elif(vec[1] < 0):\n",
    "        img = img[corte_y:,:,:]\n",
    "\n",
    "    else:\n",
    "        img = img[corte_y/2:(v_y + corte_y/2) , : , :]\n",
    "        \n",
    "    #Print dos parametros de controle\n",
    "    #print(\"Corte_X: {0}, Corte_y: {1}, x: {2}, y: {3}, var: {4}, Dx: {5}, Dy: {6}, prop: {7}\".format(corte_x, corte_y, img.shape[1], img.shape[0], var, vec[0], vec[1], x/y))\n",
    "\n",
    "    #Resize da imagem cortada para o tamanho original do frame\n",
    "    img = cv.resize(img,(x, y), interpolation = cv.INTER_LINEAR)\n",
    "    \n",
    "    #Alerta do Limite do fluxo optico atraves da mudança de cor do retangulo \n",
    "    if(np.abs(vec[0]) > 80 or np.abs(vec[1]) > 80):\n",
    "        color = (0, 0, 255)\n",
    "    \n",
    "    else:\n",
    "        color = (255, 0, 0)\n",
    "    \n",
    "    #Criação do retangulo na imagem de visualização\n",
    "    cv2.rectangle(img, (cx - rec[0] + int(vec[0]), cy - rec[1] + int(vec[1])), \n",
    "                   (cx + rec[0] + int(vec[0]), cy + rec[1] + int(vec[1])), color, 2)\n",
    "\n",
    "    \n",
    "    return frame, img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Captura da Imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "captura = cv2.VideoCapture(0)\n",
    "\n",
    "# Para não deixar encavalar os frames\n",
    "captura.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "#Condição inicial\n",
    "ret, frame_inicial = captura.read()\n",
    "\n",
    "#Vetor optical flow\n",
    "#vec = [0, 0]\n",
    "\n",
    "while(1):\n",
    "    ret, frame = captura.read()\n",
    "        \n",
    "    #frame_inicial, img = get_Traking(frame_inicial, frame, dt_params, lk_params) #Optical Flow\n",
    "    frame_inicial, img = get_DenciveTraking(frame_inicial, frame) #Densive Optical Flow\n",
    "    \n",
    "    cv2.imshow(\"Video\", img)\n",
    "\n",
    "    # Pressione ESC para sair do loop\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "captura.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
